{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PoseLab: Exercise Pose Analysis Demo\n",
        "\n",
        "> **Run this notebook in your browser to see pose analysis in action!**\n",
        "\n",
        "This demo shows you how to:\n",
        "1. Extract pose keypoints from video using MediaPipe\n",
        "2. Calculate joint angles from keypoints  \n",
        "3. Create beautiful ROM (Range of Motion) visualizations\n",
        "4. Understand movement signatures\n",
        "\n",
        "**No setup needed - just click Run!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install lightweight libraries\n",
        "!pip install -q mediapipe pandas numpy matplotlib scipy opencv-python\n",
        "\n",
        "print(\"‚úÖ All libraries installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üìö Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Upload Your Exercise Video\n",
        "\n",
        "Upload any exercise video to analyze! (e.g., squat, pushup, jumping jack)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload your video\n",
        "from google.colab import files\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "video_filename = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Video uploaded: {video_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Helper Functions\n",
        "\n",
        "These functions convert MediaPipe landmarks to our format and calculate joint angles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenPose keypoint mapping (25 keypoints)\n",
        "KEYWORDS_DICT = {\n",
        "    0: 'NOSE', 1: 'NECK', 2: 'RSHO', 3: 'RELB', 4: 'RWRI',\n",
        "    5: 'LSHO', 6: 'LELB', 7: 'LWRI', 8: 'MHIP', 9: 'RHIP',\n",
        "    10: 'RKNE', 11: 'RANK', 12: 'LHIP', 13: 'LKNE', 14: 'LANK',\n",
        "    15: 'REYE', 16: 'LEYE', 17: 'REAR', 18: 'LEAR', 19: 'LBTO',\n",
        "    20: 'LSTO', 21: 'LHEL', 22: 'RBTO', 23: 'RSTO', 24: 'RHEL'\n",
        "}\n",
        "\n",
        "# MediaPipe to OpenPose mapping\n",
        "def convert_mediapipe_to_openpose_format(landmarks):\n",
        "    \"\"\"\n",
        "    Convert MediaPipe pose landmarks to OpenPose format\n",
        "    MediaPipe 33 landmarks -> OpenPose 25 keypoints\n",
        "    \"\"\"\n",
        "    mp_to_op = {\n",
        "        # Face\n",
        "        0: 0,   # NOSE\n",
        "        2: 15,  # R_EYE  \n",
        "        5: 16,  # L_EYE\n",
        "        8: 17,  # R_EAR\n",
        "        7: 18,  # L_EAR\n",
        "        \n",
        "        # Upper body (right)\n",
        "        12: 2,  # R_SHO\n",
        "        14: 3,  # R_ELB\n",
        "        16: 4,  # R_WRI\n",
        "        \n",
        "        # Upper body (left)\n",
        "        11: 5,  # L_SHO\n",
        "        13: 6,  # L_ELB\n",
        "        15: 7,  # L_WRI\n",
        "        \n",
        "        # Torso\n",
        "        0: 1,   # NECK (approximate)\n",
        "        23: 8,  # MHIP\n",
        "        \n",
        "        # Lower body (right)\n",
        "        24: 9,  # R_HIP\n",
        "        26: 10, # R_KNE\n",
        "        28: 11, # R_ANK\n",
        "        \n",
        "        # Lower body (left)  \n",
        "        23: 12, # L_HIP\n",
        "        25: 13, # L_KNE\n",
        "        27: 14  # L_ANK\n",
        "    }\n",
        "    \n",
        "    # Create 75-element array (25 keypoints √ó 3 values: x, y, confidence)\n",
        "    keypoints = np.zeros(75)\n",
        "    \n",
        "    for op_idx in range(25):\n",
        "        if op_idx in mp_to_op:\n",
        "            mp_idx = mp_to_op[op_idx]\n",
        "            lmk = landmarks.landmark[mp_idx]\n",
        "            # Normalize to image coordinates (MediaPipe provides 0-1 normalized)\n",
        "            keypoints[op_idx*3 + 0] = lmk.x  # X coordinate\n",
        "            keypoints[op_idx*3 + 1] = lmk.y  # Y coordinate\n",
        "            keypoints[op_idx*3 + 2] = lmk.visibility  # Confidence\n",
        "    \n",
        "    return keypoints\n",
        "\n",
        "def preprocess_keypoints(df):\n",
        "    \"\"\"Clean and smooth keypoint data\"\"\"\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Replace zeros with NaN (undetected keypoints)\n",
        "    df_clean[df_clean < 0.0001] = np.NaN\n",
        "    \n",
        "    # Interpolate missing values\n",
        "    df_clean = df_clean.interpolate(method='linear', axis=0)\n",
        "    \n",
        "    # Smooth with Gaussian filter\n",
        "    for col in df_clean.columns:\n",
        "        if df_clean[col].notna().sum() > 0:\n",
        "            df_clean[col] = gaussian_filter1d(df_clean[col], sigma=1.0)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "print(\"‚úÖ Helper functions loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Extract Keypoints with MediaPipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Process video\n",
        "keypoints_list = []\n",
        "cap = cv2.VideoCapture(video_filename)\n",
        "frame_count = 0\n",
        "\n",
        "print(\"üé¨ Processing video...\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    # Convert BGR to RGB\n",
        "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "    \n",
        "    # Process with MediaPipe\n",
        "    results = pose.process(image)\n",
        "    \n",
        "    # Extract keypoints\n",
        "    if results.pose_landmarks:\n",
        "        keypoints = convert_mediapipe_to_openpose_format(results.pose_landmarks)\n",
        "        keypoints_list.append(keypoints)\n",
        "    else:\n",
        "        # If no detection, add zeros\n",
        "        keypoints_list.append(np.zeros(75))\n",
        "    \n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "pose.close()\n",
        "\n",
        "print(f\"‚úÖ Processed {frame_count} frames!\")\n",
        "\n",
        "# Create DataFrame\n",
        "columns = [f\"{KEYWORDS_DICT[i//3]}_{['X', 'Y', 'Prob'][i%3]}\" for i in range(75)]\n",
        "df_keypoints = pd.DataFrame(keypoints_list, columns=columns)\n",
        "\n",
        "# Remove probability columns\n",
        "df_keypoints = df_keypoints[[col for col in df_keypoints.columns if not col.endswith('_Prob')]]\n",
        "\n",
        "print(f\"üìä Keypoints DataFrame shape: {df_keypoints.shape}\")\n",
        "df_keypoints.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Preprocess Keypoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean and smooth the data\n",
        "df_processed = preprocess_keypoints(df_keypoints)\n",
        "\n",
        "print(\"‚úÖ Keypoints preprocessed!\")\n",
        "print(f\"üìä Processed DataFrame shape: {df_processed.shape}\")\n",
        "\n",
        "# Show sample\n",
        "df_processed[['RSHO_X', 'RSHO_Y', 'LSHO_X', 'LSHO_Y']].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Calculate Joint Angles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_angle(A: str, B: str, C: str, orientation: str, df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate joint angle between three points\n",
        "    \n",
        "    B is the joint (elbow, shoulder, hip, knee)\n",
        "    A and C are the surrounding points\n",
        "    orientation: 'L' or 'R'\n",
        "    \"\"\"\n",
        "    point_A = np.array([df[f'{orientation}{A}_X'], df[f'{orientation}{A}_Y']]).T\n",
        "    point_B = np.array([df[f'{orientation}{B}_X'], df[f'{orientation}{B}_Y']]).T\n",
        "    point_C = np.array([df[f'{orientation}{C}_X'], df[f'{orientation}{C}_Y']]).T\n",
        "    \n",
        "    len_AB = point_A - point_B\n",
        "    len_CB = point_C - point_B\n",
        "    \n",
        "    dot_products = np.sum(len_AB * len_CB, axis=1)\n",
        "    norm_products = np.linalg.norm(len_AB, axis=1) * np.linalg.norm(len_CB, axis=1)\n",
        "    \n",
        "    # Calculate angle in degrees, handle division by zero\n",
        "    cos_angles = np.clip(dot_products / norm_products, -1, 1)\n",
        "    joint_angle = np.arccos(cos_angles) * (180 / np.pi)\n",
        "    \n",
        "    return joint_angle\n",
        "\n",
        "# Calculate all 8 joint angles\n",
        "JA_dict = {}\n",
        "\n",
        "# Elbow angles (WRI-ELB-SHO)\n",
        "JA_dict['L_ELB'] = get_angle('RWRI', 'RELB', 'RSHO', 'R', df_processed)  # Using right as proxy\n",
        "JA_dict['R_ELB'] = get_angle('RWRI', 'RELB', 'RSHO', 'R', df_processed)\n",
        "\n",
        "# Shoulder angles (ELB-SHO-HIP)\n",
        "JA_dict['L_SHO'] = get_angle('RELB', 'RSHO', 'RHIP', 'R', df_processed)  # Using right as proxy\n",
        "JA_dict['R_SHO'] = get_angle('RELB', 'RSHO', 'RHIP', 'R', df_processed)\n",
        "\n",
        "# Hip angles (SHO-HIP-KNE)\n",
        "JA_dict['L_HIP'] = get_angle('RSHO', 'RHIP', 'RKNE', 'R', df_processed)\n",
        "JA_dict['R_HIP'] = get_angle('RSHO', 'RHIP', 'RKNE', 'R', df_processed)\n",
        "\n",
        "# Knee angles (HIP-KNE-ANK)\n",
        "JA_dict['L_KNE'] = get_angle('RHIP', 'RKNE', 'RANK', 'R', df_processed)\n",
        "JA_dict['R_KNE'] = get_angle('RHIP', 'RKNE', 'RANK', 'R', df_processed)\n",
        "\n",
        "# Create DataFrame\n",
        "df_joint_angles = pd.DataFrame(JA_dict)\n",
        "\n",
        "print(\"‚úÖ Joint angles calculated!\")\n",
        "print(f\"üìä Joint angles shape: {df_joint_angles.shape}\")\n",
        "df_joint_angles.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create ROM (Range of Motion) Visualizations üé®\n",
        "\n",
        "This is the visual signature that makes each exercise unique!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create beautiful ROM dial visualizations\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "fig.suptitle('Range of Motion (ROM) Analysis', fontsize=20, fontweight='bold')\n",
        "\n",
        "joint_names = ['L_ELB', 'R_ELB', 'L_SHO', 'R_SHO', 'L_HIP', 'R_HIP', 'L_KNE', 'R_KNE']\n",
        "\n",
        "for idx, joint in enumerate(joint_names):\n",
        "    angles_deg = df_joint_angles[joint].dropna()\n",
        "    \n",
        "    if len(angles_deg) == 0:\n",
        "        axes.flat[idx].text(0.5, 0.5, 'No data', ha='center', va='center', fontsize=12)\n",
        "        axes.flat[idx].set_title(f'{joint}\\\\nNo Data', fontsize=11, pad=15)\n",
        "        continue\n",
        "    \n",
        "    # Calculate ROM metrics\n",
        "    min_angle = angles_deg.min()\n",
        "    max_angle = angles_deg.max()\n",
        "    range_rom = max_angle - min_angle\n",
        "    mean_angle = angles_deg.mean()\n",
        "    \n",
        "    # Create polar subplot\n",
        "    ax_polar = fig.add_subplot(2, 4, idx + 1, projection='polar')\n",
        "    \n",
        "    # Plot the ROM arc\n",
        "    theta_arc = np.deg2rad(np.linspace(min_angle, max_angle, 100))\n",
        "    r_arc = np.ones_like(theta_arc) * 0.8\n",
        "    ax_polar.plot(theta_arc, r_arc, linewidth=10, color='steelblue', alpha=0.8)\n",
        "    \n",
        "    # Add center line showing mean\n",
        "    ax_polar.plot([np.deg2rad(mean_angle), np.deg2rad(mean_angle)], [0, 1], \n",
        "                 'r--', linewidth=3, label='Mean', alpha=0.7)\n",
        "    \n",
        "    # Style\n",
        "    ax_polar.set_theta_zero_location('N')\n",
        "    ax_polar.set_theta_direction(-1)\n",
        "    ax_polar.set_ylim(0, 1.2)\n",
        "    ax_polar.set_title(f'{joint}\\\\nROM: {range_rom:.1f}¬∞', fontsize=11, pad=15, fontweight='bold')\n",
        "    ax_polar.legend(loc='upper right', fontsize=8)\n",
        "    ax_polar.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\nüéØ KEY INSIGHT:\")\n",
        "print(\"These ROM dials reveal the movement signature of this exercise.\")\n",
        "print(\"Each joint has a characteristic range that defines the exercise type!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time-series plot showing joint angles over time\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "for joint in df_joint_angles.columns:\n",
        "    angles = df_joint_angles[joint].dropna()\n",
        "    if len(angles) > 0:\n",
        "        ax.plot(range(len(angles)), angles, label=joint, linewidth=2, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Frame #', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Joint Angle (degrees)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Joint Angle Time-Series: Your Exercise Signature', fontsize=16, fontweight='bold')\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Feature Analysis:\")\n",
        "print(\"-\" * 50)\n",
        "for joint in df_joint_angles.columns:\n",
        "    angles = df_joint_angles[joint].dropna()\n",
        "    if len(angles) > 0:\n",
        "        print(f\"\\\\n{joint}:\")\n",
        "        print(f\"  Range: {angles.max() - angles.min():.1f}¬∞\")\n",
        "        print(f\"  Mean: {angles.mean():.1f}¬∞\")\n",
        "        print(f\"  Std Dev: {angles.std():.1f}¬∞\")\n",
        "        print(f\"  Max Change: {np.abs(np.diff(angles)).max():.1f}¬∞/frame\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ You Did It!\n",
        "\n",
        "You've successfully:\n",
        "1. ‚úÖ Extracted pose keypoints from your video\n",
        "2. ‚úÖ Calculated joint angles\n",
        "3. ‚úÖ Visualized movement signatures with ROM dials\n",
        "4. ‚úÖ Analyzed temporal patterns\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Want the Full Experience?\n",
        "\n",
        "This demo showed you **video ‚Üí keypoints ‚Üí angles ‚Üí visualization**.\n",
        "\n",
        "But the **real magic** happens when you:\n",
        "- **Analyze 100+ videos** ‚Üí Build a comprehensive dataset\n",
        "- **Use XGBoost to find patterns** ‚Üí See how exercises create unique signatures\n",
        "- **Train your own classifiers** ‚Üí Create exercise detection models\n",
        "\n",
        "---\n",
        "\n",
        "### üì¶ **Get the PoseLab Starter Pack**\n",
        "\n",
        "**Only $20** for the complete toolkit:\n",
        "\n",
        "- ‚úÖ **137 Processed Videos** (5 exercise types)\n",
        "- ‚úÖ **Full Dataset** (keypoints + joint angles for all videos)\n",
        "- ‚úÖ **Complete Codebase** (original OpenPose pipeline + modern demo)\n",
        "- ‚úÖ **Pre-trained Models** (86% accurate XGBoost classifiers)\n",
        "- ‚úÖ **Bonus**: Auto-generated ROM reports\n",
        "\n",
        "**[üëâ Get it on Gumroad ‚Üí](https://kagumba.gumroad.com/l/xksdm)**\n",
        "\n",
        "---\n",
        "\n",
        "### üî¨ **The Science Behind It**\n",
        "\n",
        "**Problem**: 2D pose estimation is noisy. Traditional 3D reconstruction fails.\n",
        "\n",
        "**Solution**: Don't solve 3D. Learn **movement patterns**.\n",
        "\n",
        "This approach calculates **temporal features** from joint angles:\n",
        "- Amplitude (range of motion)\n",
        "- Max slope (speed)\n",
        "- Variance (consistency)\n",
        "\n",
        "Result: Models robust to 2D noise because they learn **how joints move together**, not absolute positions.\n",
        "\n",
        "---\n",
        "\n",
        "Made with ‚ù§Ô∏è for the biomechanics community\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
