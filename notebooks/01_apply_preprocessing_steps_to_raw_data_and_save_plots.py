# -*- coding: utf-8 -*-
"""01 - Apply Preprocessing steps to Raw Data and Save Plots

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YdwP1tCFNWkvrnHFk81hGg12gGpfYPsP

### Mount Drive
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""### Import Libraries"""

import pandas as pd
import numpy as np
import json
import os

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker 

from scipy import stats

"""### Initialize Helper Functions """

def zeros_to_nans(df):
    """If keypoint is not detected, OpenPose returns 0 for undetected keypoints"""
    df[df < 0.0001] = np.NaN
    return df

def apply_interpolation(df):
    """Fill in missing values"""
    return df.apply(lambda col: col.interpolate(), axis=0)

def remove_high_frequency_noise_with_rolling_window_function(df):
    """Apply smoothing with a Gaussian filter"""
    return df.rolling(window=5, win_type='gaussian', center=True).mean(std=5)


def apply_preprocessing_steps(df):

    df_processed = df.copy()
    df_processed = zeros_to_nans(df_processed)
    df_processed = apply_interpolation(df_processed)
    df_processed = remove_high_frequency_noise_with_rolling_window_function(df_processed)

    return df_processed


keywords_dict = {
       0 : 'NOSE',  1 : 'NECK',  2 : 'RSHO',  3 : 'RELB',  4 : 'RWRI',
       5 : 'LSHO',  6 : 'LELB',  7 : 'LWRI',  8 : 'MHIP',  9 : 'RHIP',
      10 : 'RKNE', 11 : 'RANK', 12 : 'LHIP', 13 : 'LKNE', 14 : 'LANK',
      15 : 'REYE', 16 : 'LEYE', 17 : 'REAR', 18 : 'LEAR', 19 : 'LBTO',
      20 : 'LSTO', 21 : 'LHEL', 22 : 'RBTO', 23 : 'RSTO', 24 : 'RHEL'
      }

def save_plot_as_array_of_subplots(df, plot_name, save_path):
    """
    Saves plot in path, no return type
    Serves as a quick view of what the csv data looks like
    """
    fig, axs = plt.subplots(5, 5, figsize=(25, 25), constrained_layout=True)

    for ax, val in zip(axs.flat, keywords_dict.values()):

        ax.set_title(f'{val}')
        ax.set_xlabel('Time (%)', fontsize=10)
        ax.set_ylabel(f'{val}-Position', fontsize=10)

        ax.plot(df[f'{val}_X'], label=f'{val}_X')
        ax.plot(df[f'{val}_Y'], label=f'{val}_Y')

        ax.legend()
        ax.margins(x=0.01)
        
        ax.xaxis.set_major_locator(ticker.MultipleLocator(len(df)/5))
        ax.xaxis.set_minor_locator(ticker.MultipleLocator(len(df)/20))
        ax.xaxis.set_major_formatter(ticker.PercentFormatter(xmax=len(df)))
    
    fig.suptitle(plot_name, fontsize=25)
    plt.savefig(save_path)
    plt.close(fig)

"""### Configure Save Paths"""

PROJ_SAVE_ROOT = os.path.join('/content/gdrive/MyDrive/ColabNotebooks/BiomechanicsAnalysis/___WORKOUTS/data/tests/processed')

exercises_list = os.listdir(PROJ_SAVE_ROOT)

for exercise_folder in exercises_list:
    exercise_samples =  os.listdir(os.path.join(PROJ_SAVE_ROOT, exercise_folder))

    print(exercise_folder)
    for sample in exercise_samples:

        print(f'\t{sample}')

        # Define paths
        sample_csv_path = os.path.join(PROJ_SAVE_ROOT, exercise_folder, sample, f'{sample}.csv')
        raw_plot_path = os.path.join(PROJ_SAVE_ROOT, exercise_folder, sample, f'{sample}_plot_raw.png')

        processed_data_path = os.path.join(PROJ_SAVE_ROOT, exercise_folder, sample, f'{sample}_data_processed.csv')
        processed_plot_path = os.path.join(PROJ_SAVE_ROOT, exercise_folder, sample, f'{sample}_plot_processed.png')

        # Apply processing steps
        df = pd.read_csv(sample_csv_path, index_col=0)
        df_processed = apply_preprocessing_steps(df)

        #Save data
        save_plot_as_array_of_subplots(df, sample, raw_plot_path)
        print(f'\t\t{sample:20} raw plot saved')

        df_processed.to_csv(processed_data_path)  
        print(f'\t\t{sample:20} processed data saved')

        save_plot_as_array_of_subplots(df_processed, sample, processed_plot_path)
        print(f'\t\t{sample:20} processed plot saved')